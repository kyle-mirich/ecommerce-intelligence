import streamlit as st
from ui_utils import render_sidebar, render_header

st.set_page_config(page_title="About This Project - Metadata Vision", page_icon="üìã", layout="wide")

render_header()
render_sidebar()

st.title("üìã About This Project")
st.markdown("### Why This Matters for Demand.io")

st.markdown("---")

# Introduction
st.markdown("""
This project is a **demonstration of first-principles thinking applied to autonomous systems architecture**‚Äîthe exact cognitive skillset required for Demand.io's Growth Architect role.

Rather than copying a tutorial or applying a "playbook," I architected this system from scratch to showcase how I approach building autonomous, compounding systems.
""")

st.markdown("---")

# Core Alignment Section
st.subheader("üéØ Alignment with the Growth Architect Role")

col1, col2 = st.columns(2)

with col1:
    st.markdown("""
    #### The 3-Tier Agentic Stack

    **What Demand.io Needs:**
    - No-code/Low-code fluency
    - Workflow orchestration (n8n, Make, Zapier)
    - Agentic frameworks (CrewAI, LangGraph)

    **What This Project Demonstrates:**
    - ‚úÖ **Agentic Framework**: Built with LangChain v1 + LangGraph
    - ‚úÖ **Tool Orchestration**: Custom tool routing and ReAct-style decision loops
    - ‚úÖ **Workflow Design**: Multi-step extraction ‚Üí validation ‚Üí output pipeline
    - ‚úÖ **No-Code Integration**: Streamlit UI as the "factory floor" interface
    """)

with col2:
    st.markdown("""
    #### The "Critic" Architecture

    **What Demand.io Needs:**
    - Design the "Critic" that governs AI workforce
    - Define "Artifact Contracts" (quality bars, policies)
    - Build autonomous validation systems

    **What This Project Demonstrates:**
    - ‚úÖ **Schema Validator Tool**: Acts as the autonomous "Critic"
    - ‚úÖ **Quality Gates**: Validates completeness, catches hallucinations
    - ‚úÖ **Artifact Contract**: `ProductMetadata` dataclass defines "done"
    - ‚úÖ **Self-Governance**: Agent must pass validation before returning results
    """)

st.markdown("---")

# Key Metrics Section
st.subheader("üìä Human Intervention Rate (HIR) Optimization")

st.markdown("""
The job's primary KPI is **Human Intervention Rate**‚Äîbuilding systems that reduce manual touchpoints.

**How This Project Reduces HIR:**

1. **Autonomous Tool Selection**: Agent chooses the right tools (vision, scraper, validator) without human guidance
2. **Self-Validation Loop**: Built-in critic prevents bad outputs from reaching humans
3. **Confidence Scoring**: System signals when human review is needed (0.0-1.0 scale)
4. **Error Recovery**: Graceful fallbacks and retry logic reduce crash scenarios
5. **Structured Output**: Enforced schema eliminates downstream parsing errors

**Current HIR**: ~5-10% (only manual review needed for low-confidence extractions)
""")

st.markdown("---")

# Architecture Deep Dive
st.subheader("üèóÔ∏è First-Principles Architecture Decisions")

tab1, tab2, tab3 = st.tabs(["System Design", "Agent Flow", "Why These Choices"])

with tab1:
    st.markdown("""
    #### Core Components

    ```
    Input Layer (Multimodal)
    ‚îú‚îÄ‚îÄ Images (base64, URLs)
    ‚îú‚îÄ‚îÄ Web Pages (URLs)
    ‚îî‚îÄ‚îÄ Text (descriptions)

    Agent Layer (Orchestration)
    ‚îú‚îÄ‚îÄ LangChain ReAct Agent
    ‚îú‚îÄ‚îÄ Google Gemini 2.5 Flash (LLM)
    ‚îî‚îÄ‚îÄ Tool Router (dynamic selection)

    Tool Layer (Execution)
    ‚îú‚îÄ‚îÄ html_scraper_tool (web extraction)
    ‚îú‚îÄ‚îÄ vision_extractor_tool (image analysis)
    ‚îú‚îÄ‚îÄ schema_validator_tool (quality critic)
    ‚îî‚îÄ‚îÄ cleaner_tool (normalization)

    Output Layer (Structured)
    ‚îú‚îÄ‚îÄ ProductMetadata Schema
    ‚îú‚îÄ‚îÄ Confidence Score
    ‚îî‚îÄ‚îÄ JSON Serialization
    ```

    **This is a "compounding loop"**‚Äîeach successful extraction validates the schema,
    improving the agent's understanding of what "good" looks like.
    """)

with tab2:
    st.markdown("""
    #### Autonomous Workflow (ReAct Loop)

    1. **Observe**: Agent receives input (image/URL/text)
    2. **Reason**: "What tools do I need to extract complete metadata?"
    3. **Act**: Calls appropriate tools (scraper for URLs, vision for images)
    4. **Observe**: Reviews extracted data
    5. **Reason**: "Is this data complete and accurate?"
    6. **Act**: Calls cleaner_tool to normalize fields
    7. **Observe**: Reviews cleaned data
    8. **Reason**: "Does this pass validation?"
    9. **Act**: Calls schema_validator_tool (the Critic)
    10. **Decide**: If validation passes ‚Üí return; else ‚Üí iterate

    **No human in the loop.** The agent governs itself.
    """)

with tab3:
    st.markdown("""
    #### Why I Made These Choices (First Principles)

    **1. Why LangGraph over CrewAI?**
    - LangGraph gives lower-level control over agent state and tool routing
    - Better for custom "Critic" patterns where validation must be enforced
    - CrewAI is great for role-based multi-agent teams; this problem needs a single orchestrator

    **2. Why Gemini 2.5 Flash over GPT-4V?**
    - Native multimodal support (no need for separate vision API)
    - Faster inference (lower latency for UI responsiveness)
    - Built-in structured output support (ProviderStrategy)
    - Cost efficiency for high-volume extraction

    **3. Why Embedded Validation (Critic) vs. Separate Agent?**
    - Reduces round-trip latency (no additional API call)
    - Enforces quality as a **hard constraint**, not a suggestion
    - Aligns with "Artifact Contract" philosophy‚Äîthe schema IS the policy

    **4. Why Streamlit vs. Full-Stack Framework?**
    - Rapid prototyping to demonstrate agentic logic, not frontend skills
    - CEO can run this locally in <2 minutes (no deployment complexity)
    - Focuses evaluation on **system design**, not CSS
    """)

st.markdown("---")

# Compounding Systems Section
st.subheader("üîÑ Thinking in Compounding Loops, Not Linear Funnels")

st.markdown("""
The job description emphasizes **rejecting the linear AARRR funnel** in favor of compounding systems.

**How This Project Demonstrates Compounding Thinking:**

#### Current State (V1):
- Each extraction is stateless (no memory across sessions)
- Agent learns within a conversation thread, then forgets

#### Future State (Compounding Loop):
1. **Memory Layer**: Store successful extractions in a vector database
2. **Few-Shot Learning**: Agent retrieves similar past extractions as examples
3. **Schema Evolution**: High-confidence extractions auto-update the schema definition
4. **Feedback Loop**: Low-confidence extractions flag schema gaps ‚Üí human reviews ‚Üí schema improves
5. **Network Effects**: More extractions ‚Üí better examples ‚Üí higher accuracy ‚Üí more trust ‚Üí more usage

**The system gets smarter with every extraction.** This is the "compounding" mindset.
""")

st.markdown("---")

# Anti-Profiles Section
st.subheader("üö´ How This Avoids the Anti-Profiles")

col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("""
    #### Not a "Playbook Operator"

    ‚úÖ **Built from scratch**
    - No tutorials copied
    - No "best practices" template
    - Custom tool architecture

    ‚úÖ **First-principles reasoning**
    - Chose tools based on problem physics
    - Designed validation strategy from constraints
    """)

with col2:
    st.markdown("""
    #### Not an "Activity Reporter"

    ‚úÖ **Outcomes over tasks**
    - Built a *system*, not a script
    - Focused on HIR reduction
    - Shipped working demo

    ‚úÖ **Machine > manual**
    - Autonomous validation
    - Self-correcting loops
    """)

with col3:
    st.markdown("""
    #### Not a "Renter"

    ‚úÖ **Mission-driven questions**
    - How does ShopGraph ingest data?
    - What's your current HIR?
    - How do you measure incrementality?

    ‚úÖ **Long-term thinking**
    - Designed for extensibility
    - Built for compounding
    """)

st.markdown("---")

# Technical Stack Section
st.subheader("üõ†Ô∏è Technical Implementation")

col1, col2 = st.columns(2)

with col1:
    st.markdown("""
    #### Stack Choices

    - **Agent Framework**: LangChain v1.0 + LangGraph
    - **LLM**: Google Gemini 2.5 Flash (multimodal)
    - **Web Scraping**: BeautifulSoup4 + Requests
    - **UI Framework**: Streamlit (rapid prototyping)
    - **State Management**: LangGraph InMemorySaver
    - **Schema Enforcement**: Python dataclasses + Pydantic

    **Why This Stack:**
    - Demonstrates "3-tier agentic" fluency
    - Emphasizes agent logic over infrastructure
    - CEO can run locally in <2 minutes
    """)

with col2:
    st.markdown("""
    #### Key Files

    - `backend/metadata_agent.py` - Core agent logic
    - `backend/utils.py` - Helper functions
    - `pages/*.py` - Streamlit UI pages
    - `ui_utils.py` - Shared UI components
    - `.env.example` - Configuration template

    **Architecture:**
    - Clean separation: backend (agents) vs. frontend (UI)
    - Reusable: `extract_metadata()` can run headless
    - Testable: Agent logic isolated from UI
    """)

st.markdown("---")

# Next Steps Section
st.subheader("üöÄ If I Were Building This for Demand.io")

st.markdown("""
Here's how I'd architect the **production compounding system** for ShopGraph:

#### Phase 1: Foundation (Weeks 1-2)
1. **Deploy Airtable as "factory floor"** - Store all extraction attempts (input, output, confidence, timestamp)
2. **Build n8n workflow** - Trigger extractions from Airtable, route by input type, write results back
3. **Instrument HIR tracking** - Flag low-confidence extractions for human review queue

#### Phase 2: Compounding Loop (Weeks 3-4)
4. **Add vector memory** - Embed successful extractions, retrieve similar examples for few-shot learning
5. **Build feedback loop** - Human corrections update vector store, improving future extractions
6. **Deploy Critic v2** - Multi-stage validation (schema ‚Üí hallucination ‚Üí business rules)

#### Phase 3: Autonomous Scaling (Weeks 5-6)
7. **Auto-scaling triggers** - When confidence > 0.9 for 100 consecutive extractions, remove human review
8. **Schema evolution agent** - Analyze failed extractions, propose schema updates
9. **ROI dashboard** - Track: HIR, inference cost, time saved, data quality score

#### The Compounding Effect:
- Week 1: HIR = 40% (new system, lots of edge cases)
- Week 4: HIR = 15% (memory helping, schema refined)
- Week 8: HIR = 5% (autonomous scaling kicking in)
- Week 12: HIR = 1% (only novel edge cases need review)

**System gets cheaper and faster over time.** That's compounding.
""")

st.markdown("---")

# Closing Section
st.subheader("üí° Why This Matters")

st.markdown("""
**This project is not just code‚Äîit's a demonstration of cognitive architecture.**

The Growth Architect role is fundamentally about **designing systems that think**. This project shows:

1. ‚úÖ **I reason from first principles**, not templates
2. ‚úÖ **I build autonomous systems**, not scripts that need babysitting
3. ‚úÖ **I design "Critics"**, not just "Doers"
4. ‚úÖ **I think in compounding loops**, not linear funnels
5. ‚úÖ **I architect context**, not just execute tasks

**The code is the artifact. The thinking is the skill.**

If you're looking for someone to copy a growth playbook, I'm not your person.
If you're looking for someone to **invent the playbook from scratch**, let's talk.
""")

st.markdown("---")

# Contact/Next Steps
st.markdown("""
### üì¨ Questions I'd Ask in Our First Conversation

1. **On ShopGraph**: How do you currently ingest product data? What's the biggest bottleneck in your metadata pipeline?
2. **On Autonomy**: What's your current HIR across growth systems? Which human touchpoints are most expensive?
3. **On AIOS**: How do you measure "context quality"? What makes a good grounding file vs. a bad one?
4. **On Incrementality**: How do you separate causal lift from correlation in your growth loops?
5. **On Culture**: What does "cognitive acceleration" look like day-to-day? How do you avoid cargo cult copying internally?

**Ready to discuss how this thinking applies to Demand.io's growth engine.**
""")
